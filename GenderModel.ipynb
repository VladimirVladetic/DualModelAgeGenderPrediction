{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPFC7YZ6bXbw1ZO7kVsVrJE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VladimirVladetic/DualModelAgeGenderPrediction/blob/main/GenderModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rQ6KZDWALbsd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input, BatchNormalization\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import zipfile\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.regularizers import l1_l2, l1, l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img\n",
        "import shutil\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "source_path = '/content/kaggle.json'\n",
        "destination_path = '/root/.kaggle/kaggle.json'\n",
        "kaggle_dir = '/root/.kaggle/'\n",
        "if not os.path.exists(kaggle_dir):\n",
        "    os.makedirs(kaggle_dir)\n",
        "os.rename(source_path, destination_path)"
      ],
      "metadata": {
        "id": "ai5zIYdbLkYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d jangedoo/utkface-new\n",
        "\n",
        "with zipfile.ZipFile('/content/utkface-new.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('/content')\n",
        "\n",
        "folder_to_delete = '/content/sample_data'\n",
        "shutil.rmtree(folder_to_delete)\n",
        "folder_to_delete = '/content/crop_part1'\n",
        "shutil.rmtree(folder_to_delete)\n",
        "folder_to_delete = '/content/utkface_aligned_cropped'\n",
        "shutil.rmtree(folder_to_delete)"
      ],
      "metadata": {
        "id": "2L4dsjlMLlrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_paths_age_gender_labels(image_directory):\n",
        "    image_paths = []\n",
        "    age_labels = []\n",
        "    gender_labels = []\n",
        "    for filename in tqdm(os.listdir(image_directory )):\n",
        "        image_path = os.path.join(image_directory,filename)\n",
        "        temporary_data = filename.split(\"_\")\n",
        "        age = int(temporary_data[0])\n",
        "        gender = int(temporary_data[1])\n",
        "        image_paths.append(image_path)\n",
        "        age_labels.append(age)\n",
        "        gender_labels.append(gender)\n",
        "    return image_paths, age_labels, gender_labels"
      ],
      "metadata": {
        "id": "MIQMexfSLnaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_age_to_category(age):\n",
        "  age_ranges = [(0, 2), (3, 9), (10, 20), (21, 29), (30, 45), (46, 60), (61, 80), (81, 120)]\n",
        "  for category, (min_age, max_age) in enumerate(age_ranges, start=0):\n",
        "          if min_age <= age <= max_age:\n",
        "              return category\n",
        "  return 0"
      ],
      "metadata": {
        "id": "dHqrqDYYLo6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_gender(df):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    df['gender'].value_counts().plot(kind='bar', color=['blue', 'pink'])\n",
        "    plt.title('Gender Distribution')\n",
        "    plt.xlabel('Gender')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "anZEfa-DLvCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(images, height, width):\n",
        "    features = []\n",
        "    for image in tqdm(images):\n",
        "        var_img = load_img(image, color_mode='grayscale')\n",
        "        var_img = var_img.resize((height,width), Image.ANTIALIAS)\n",
        "        var_img = np.array(var_img)\n",
        "        ## Normalization of images\n",
        "        var_img = var_img / 255.0\n",
        "        features.append(var_img)\n",
        "    features = np.array(features)\n",
        "    features = features.reshape(len(features), height, width, 1)\n",
        "    ## from float64 to float32\n",
        "    features = np.array(features, dtype=np.float32)\n",
        "    return features"
      ],
      "metadata": {
        "id": "F5fMnqa8LwWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    conv_1 = Conv2D(32, kernel_size=(3,3), activation='relu', padding='same')(inputs)\n",
        "    batch_1 = BatchNormalization()(conv_1)\n",
        "    conv_2 = Conv2D(64, kernel_size=(3,3), activation='relu', padding='same')(batch_1)\n",
        "    batch_2 = BatchNormalization()(conv_2)\n",
        "\n",
        "    maxpool_1 = MaxPooling2D(pool_size=(2,2))(batch_2)\n",
        "    dropout_1 = Dropout(0.25)(maxpool_1)\n",
        "\n",
        "    conv_3 = Conv2D(128, kernel_size=(3,3), activation='relu', padding='same')(dropout_1)\n",
        "    batch_3 = BatchNormalization()(conv_3)\n",
        "    conv_4 = Conv2D(128, kernel_size=(3,3), activation='relu', padding='same')(batch_3)\n",
        "    batch_4 = BatchNormalization()(conv_4)\n",
        "\n",
        "    maxpool_2 = MaxPooling2D(pool_size=(2,2))(batch_4)\n",
        "    dropout_2 = Dropout(0.25)(maxpool_2)\n",
        "\n",
        "    conv_5 = Conv2D(256, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(dropout_2)\n",
        "    batch_5 = BatchNormalization()(conv_5)\n",
        "    conv_6 = Conv2D(256, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(batch_5)\n",
        "    batch_6 = BatchNormalization()(conv_6)\n",
        "\n",
        "    maxpool_3 = MaxPooling2D(pool_size=(2,2))(batch_6)\n",
        "    dropout_3 = Dropout(0.25)(maxpool_3)\n",
        "\n",
        "    conv_7 = Conv2D(256, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(dropout_3)\n",
        "    batch_7 = BatchNormalization()(conv_7)\n",
        "\n",
        "    flatten = Flatten()(batch_7)\n",
        "\n",
        "    dense_1 = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(flatten)\n",
        "\n",
        "    dropout_1 = Dropout(0.3)(dense_1)\n",
        "\n",
        "    dense_2 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(dropout_1)\n",
        "\n",
        "    output = Dense(1, activation='sigmoid', name=\"gender_out\")(dense_2)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[output])\n",
        "    return model"
      ],
      "metadata": {
        "id": "DoiDCzq8LzAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_directory = \"/content/UTKFace/\"\n",
        "\n",
        "image_paths, age_labels, gender_labels = get_image_paths_age_gender_labels(image_directory)\n",
        "\n",
        "age_categories = [map_age_to_category(age) for age in age_labels]\n",
        "\n",
        "gender_dictionary = {0:\"Male\",1:\"Female\"}"
      ],
      "metadata": {
        "id": "vGMKcfIUL1dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.DataFrame()\n",
        "combined_df = pd.DataFrame({'image': image_paths, 'age': age_categories})\n",
        "\n",
        "image_height = 128\n",
        "image_width = 128\n",
        "num_age_classes = 8"
      ],
      "metadata": {
        "id": "T4M27VRyL635"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_df)"
      ],
      "metadata": {
        "id": "x3bdc_R5L8KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = extract_features(combined_df[\"image\"],image_height,image_width)\n",
        "\n",
        "y_gender = np.array(df[\"gender\"])\n",
        "\n",
        "y_gender_tensor = tf.convert_to_tensor(y_gender, dtype=tf.float32)\n",
        "\n",
        "input_shape = (image_height,image_width,1)"
      ],
      "metadata": {
        "id": "yx49TjeHL-cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X))\n",
        "print(len(y_gender_tensor))"
      ],
      "metadata": {
        "id": "z98Y0f_hMGkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_gender(combined_df)"
      ],
      "metadata": {
        "id": "zm4kvuW4MJ-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(learning_rate=0.01)\n",
        "\n",
        "model = create_model(input_shape, num_age_classes)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer = opt, metrics='accuracy' )\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=5)\n",
        "\n",
        "history = model.fit(x=X, y=y_gender_tensor, batch_size=64, epochs=50, validation_split=0.2, callbacks=[lr_scheduler, early_stopping])"
      ],
      "metadata": {
        "id": "8mqwJh6nMNdi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}